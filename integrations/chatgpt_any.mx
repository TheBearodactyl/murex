if { runtime --event-types -> match onPreview } else {
    return
}

/#
    Example request:

        curl https://api.openai.com/v1/chat/completions \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -d '{
            "model": "gpt-3.5-turbo",
            "messages": [
            {
                "role": "system",
                "content": "You are a helpful assistant."
            },
            {
                "role": "user",
                "content": "Hello!"
            }
            ]
        }'

    Example response:

        {
            "id": "chatcmpl-123",
            "object": "chat.completion",
            "created": 1677652288,
            "model": "gpt-3.5-turbo-0125",
            "system_fingerprint": "fp_44709d6fcb",
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "\n\nHello there, how may I assist you today?",
                },
                "logprobs": null,
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21
            }
        }
#/

config define openai preview-exec-api %{
    Description: "OpenAI API key with write access to /v1/chat/completions"
    DataType:    str
    Default:     ""
}

config define openai preview-exec-prompt %{
    Description: "How ChatGPT should structure it's response for the [f1] preview of external executables"
    DataType:    str
    Default:     %(You are a command line cheat sheet for command line usage. When asked how to use a command
                line tool, you will provide several sections.
                
                The first section is a description of that command.
                
                The second section is only displayed if additional context of the full command line is
                provided. Then your response should then also include specific and detailed descriptions of
                that command line, and specifically any flags included within that command line. You should
                explain in detail what those flags do, why you might want to use them, and any risks that
                might arise because of their usage.
                
                The third section is commonly used examples of that tool, demonstrating other flags that are
                supported by the tool. You should not repeat any flags used in the context command line and
                there should be several examples.
                
                The forth section will be uncommon examples, ideally still likely to be useful but ultimately
                intended to demonstrate the flexibility of that tool. These examples should be other flags
                that differ from both the common examples and also those used in the command line context.

                Each section should be separated by a title.

                Your output should be formatted as plain text in a way that is easy to read from the
                command line.)
}

config define openai preview-exec-model %{
    Description: "ChatGPT model to use"
    DataType:    str
    Default:     "gpt-3.5-turbo"
}

config define openai preview-exec-send-cmdline %{
    Description: "Should Murex also include the full command line for context specific help?"
    DataType:    bool
    Default:     false
}

event onPreview chatgpt=exec {
    cast str

    $EVENT_RETURN.CacheTTL = 0

    config get openai preview-exec-prompt       -> set prompt
    config get openai preview-exec-api          -> set openai_api
    config get openai preview-exec-model        -> set model
    config get openai preview-exec-send-cmdline -> set inc_cmdline

    $EVENT_RETURN.CacheCmdLine = $inc_cmdline # cache mode, command name or full command line

    !if { $openai_api } then {
        out "This feature requires an OpenAI API key with write access to /v1/chat/completions. eg\n"
        out "config set openai preview-exec-api xxxxx\n"
        out "Run `murex-docs integrations/chatgpt` for more details or visit:"
        out "https://murex.rocks/integrations/chatgpt"
        return
    }

    <stdin> -> set event

    if { $inc_cmdline } then {
        $context = "For context, my full command line is `$(event.Interrupt.CmdLine)`."
    } else {
        $context = ""
    }

    config set http timeout 120
    config set http headers %{
        api.openai.com: {
            Authorization: "Bearer $(openai_api)"
        }
    }

    trypipe {
        %{
            model:    $model
            messages: [
                {
                    role:    system,
                    content: $prompt
                }
                {
                    role:    user,
                    content: "How do I use `$(event.Interrupt.PreviewItem)` in ${os}? $context"
                }
            ]
        } -> post https://api.openai.com/v1/chat/completions -> [ Body ] -> set json body

        if { $body.error } then {
            $body -> pretty

        } else {
            $EVENT_RETURN.CacheTTL = 60*60*24*30 # 50 days
            $body.choices.0.message.content      # print output
        }
    }
}